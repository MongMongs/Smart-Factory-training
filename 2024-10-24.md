# - OpenCV


## - filter 


### - 필터 차이점


![image](https://github.com/user-attachments/assets/cf67a662-530f-4ac7-9b83-0942966121b9)


### - HueThresholdWinForm


- 폼 구성

![image](https://github.com/user-attachments/assets/06371695-c6e9-4d4f-8dff-5156f2fcf6ab)


```
using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
using OpenCvSharp;
using OpenCvSharp.Extensions;

namespace WinFormsApp44
{
    public partial class Form1 : Form
    {
        private int hueMin = 0;
        private int hueMax = 255;


        private Mat originalImage;
        public Form1()
        {
            InitializeComponent();

            // 트랙바 초기화 및 이벤트 연결
            tbHue01.Maximum = 255;
            tbHue02.Maximum = 255;

            tbHue01.Scroll += TbHue01_Scroll;
            tbHue02.Scroll += TbHue02_Scroll;

            // 예시 이미지 로드
            LoadOriginalImage();
        }

        private void LoadOriginalImage()
        {
            originalImage = Cv2.ImRead("C:\\Temp\\cv_imgs\\newjeans.jpg");  // 원본 이미지 파일 경로
            picOrigin.Image = OpenCvSharp.Extensions.BitmapConverter.ToBitmap(originalImage);
        }

        private void TbHue01_Scroll(object sender, EventArgs e)
        {
            hueMin = tbHue01.Value;
            textHue01.Text = $"Hue_th1 : {hueMin}";
            ApplyHueFilter();  // 필터 적용
        }

        private void TbHue02_Scroll(object sender, EventArgs e)
        {
            hueMax = tbHue02.Value;
            textHue02.Text = $"Hue_th2 : {hueMax}";
            ApplyHueFilter();  // 필터 적용
        }
        private void ApplyHueFilter()
        {
            if (originalImage == null) return;

            // 이미지를 HSV 색상으로 변환
            Mat hsvImage = new Mat();
            Cv2.CvtColor(originalImage, hsvImage, ColorConversionCodes.BGR2HSV);

            // Hue 범위에 따라 필터링
            Mat mask = new Mat();
            Cv2.InRange(hsvImage, new Scalar(hueMin, 50, 50), new Scalar(hueMax, 255, 255), mask);

            // 결과를 picHue에 표시
            picHue.Image = OpenCvSharp.Extensions.BitmapConverter.ToBitmap(mask);
        }

        private void tbHue01_Scroll_1(object sender, EventArgs e)
        {

        }
    }
}
```


### - 실행 결과


- 시작 화면

![image](https://github.com/user-attachments/assets/2298136b-b7a1-4d2e-9b7b-ab05877fef6c)


- 트랙바 1(tbHue01) 만 드래그


![image](https://github.com/user-attachments/assets/8808e33f-6ce5-43f9-b821-bd4cbe6a7b92)
![image](https://github.com/user-attachments/assets/389254fd-bfe4-4716-ac25-fe4278a1a5c1)


- 트랙바 2(tbHue02) 드래그


![image](https://github.com/user-attachments/assets/71e39ea2-646e-4fab-831a-743e6d5df7e5)
![image](https://github.com/user-attachments/assets/21e32799-ce6b-4b35-9522-9869c0d47170)


### - 이미지 블러 처리


```
using OpenCvSharp;
using System;

namespace _20241024_Blurring01
{
    internal class Program
    {
        static void Filter(Mat img, out Mat dst, Mat mask)
        {
            dst = new Mat(img.Size(), MatType.CV_32F, Scalar.All(0));
            Point h_m = new Point(mask.Width / 2, mask.Height / 2);

            for (int i = h_m.Y; i < img.Rows - h_m.Y; i++)
            {
                for (int k = h_m.X; k < img.Cols - h_m.X; k++)
                {
                    float sum = 0;
                    for (int u = 0; u < mask.Rows; u++)
                    {
                        for (int v = 0; v < mask.Cols; v++)
                        {
                            int y = i + u - h_m.Y;
                            int x = k + v - h_m.X;
                            sum += mask.At<float>(u, v) * img.At<Vec3b>(y, x)[0];  // 그레이스케일 단순화
                        }
                    }
                    dst.Set<float>(i, k, sum);
                }
            }
        }

        static void Main(string[] args)
        {
            Mat image = Cv2.ImRead("C:\\Temp\\cv_imgs\\filter_blur.jpg", ImreadModes.Grayscale);
            if (image.Empty())
            {
                Console.WriteLine("이미지를 로드할 수 없습니다.");
                return;
            }

            float[] data1 =
            {
                1/9f, 1/9f, 1/9f,
                1/9f, 1/9f, 1/9f,
                1/9f, 1/9f, 1/9f
            };
            float[] data2 =
            {
                1/25f, 1/25f, 1/25f, 1/25f, 1/25f,
                1/25f, 1/25f, 1/25f, 1/25f, 1/25f,
                1/25f, 1/25f, 1/25f, 1/25f, 1/25f,
                1/25f, 1/25f, 1/25f, 1/25f, 1/25f,
                1/25f, 1/25f, 1/25f, 1/25f, 1/25f
            };

            //Mat mask = new Mat(3, 3, MatType.CV_32F, data1); //Error
            Mat mask = new Mat(5, 5, MatType.CV_32F);

            for (int i = 0; i < mask.Rows; i++)
            {
                for (int k = 0; k < mask.Cols; k++)
                {
                    mask.Set<float>(i, k, data2[i * mask.Cols + k]);
                }
            }

            Filter(image, out Mat blur, mask);

            blur.ConvertTo(blur, MatType.CV_8U);

            Cv2.ImShow("image", image);
            Cv2.ImShow("blur", blur);

            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


- 원본 이미지


![image](https://github.com/user-attachments/assets/066dcf05-2b57-48a1-9f9b-3d65f2ac6759)


- 블러 처리된 이미지


![image](https://github.com/user-attachments/assets/4707acf0-8a7a-481f-b1e8-ba26bf2243dd)



### - 가우시안 블러(Gaussian Blur)


```
using OpenCvSharp;
using System;
using System.Collections.Generic;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace BluringDirect
{
    internal class Program
    {
        static void Main(string[] args)
        {
            string path = @"C:\\Temp\\cv_imgs\\filter_blur.jpg";
            Mat src = Cv2.ImRead(path, ImreadModes.Grayscale);

            if (src.Empty())
                throw new Exception("이미지 문제발생");

            Mat blur = new Mat();

            // OpenCV 함수인 GaussianBlur를 사용하여 블러링 처리
            Cv2.GaussianBlur(src, blur, new OpenCvSharp.Size(5, 5), 0); //Size 함수의 3을 5로 바꾸면 5 * 5 필터가 되고 1/25f가 입력됨

            Cv2.ImShow("src", src);
            Cv2.ImShow("blur", blur);

            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


- 원본 이미지


![image](https://github.com/user-attachments/assets/7f71f4fb-0111-491f-baf6-2b25d390fa39)


- 가우시안 블러 처리된 이미지


![image](https://github.com/user-attachments/assets/065429d1-8260-47fa-8b50-1a6d35205d6f)



### - 샤프닝(Sharpening)


샤프닝이란?

블러링이 이웃 화소의 차이를 감소시켜서 부드럽게 만드는 것이라면, 샤프닝은 반대로 입력 화소에서 이웃 화소끼리 차이를 크게 되도록 출력 화소를 만들어서 날카로운 느낌이 나게 만드는 것이다.

이는 OpenCV 내장 함수 대신, 각 픽셀에 대해 커널을 직접 적용하여 새로운 값을 계산하는 방식이다.

(참고 자료 : https://atonlee.t7 istory.com/11)

```
using OpenCvSharp;

namespace _20241024_Sharpening01
{
    internal class Program
    {
        // 회선함수 (Filter) 동일
        // 이미지의 각 픽셀에 대해 마스크를 적용해 그 값을 새로 계산합니다.
        // 이미지를 순차적으로 순회하면서 커널을 각 픽셀에 적용하는 방식으로, **중심점(h_m)**을 기준으로 마스크가 이미지 전체에 걸쳐 적용됩니다.
        // 픽셀 단위로 값을 읽어와 커널 값과 곱해 더한 후, 결과를 출력 이미지에 설정하는 방식입니다.
        static void Filter(Mat img, out Mat dst, Mat mask)
        {
            dst = new Mat(img.Size(), MatType.CV_32F, Scalar.All(0));
            Point h_m = new Point(mask.Width / 2, mask.Height / 2);

            for (int i = h_m.Y; i < img.Rows - h_m.Y; i++)
            {
                for (int k = h_m.X; k < img.Cols - h_m.X; k++)
                {
                    float sum = 0;
                    for (int u = 0; u < mask.Rows; u++)
                    {
                        for (int v = 0; v < mask.Cols; v++)
                        {
                            int y = i + u - h_m.Y;
                            int x = k + v - h_m.X;
                            sum += mask.At<float>(u, v) * img.At<byte>(y, x);
                        }
                    }
                    dst.Set<float>(i, k, sum);
                }
            }
        }

        static void Main(string[] args)
        {
            string path = @"C:\\Temp\\cv_imgs\\filter_sharpen.jpg";
            Mat src = Cv2.ImRead(path, ImreadModes.Grayscale);

            if (src.Empty())
                throw new Exception("Failed to load image");

            float[] data1 =
            {
                0, -1, 0,
                -1, 5, -1,
                0, -1, 0
            };

            float[] data2 =
            {
                -1, -1, -1,
                -1, 9, -1,
                -1, -1, -1
            };

            Mat mask1 = new Mat(3, 3, MatType.CV_32F);
            Mat mask2 = new Mat(3, 3, MatType.CV_32F);

            // data1 값을 mask1에 설정
            for (int i = 0; i < mask1.Rows; i++)
            {
                for (int j = 0; j < mask1.Cols; j++)
                {
                    mask1.Set<float>(i, j, data1[i * mask1.Cols + j]);
                }
            }

            // data2 값을 mask2에 설정
            for (int i = 0; i < mask2.Rows; i++)
            {
                for (int j = 0; j < mask2.Cols; j++)
                {
                    mask2.Set<float>(i, j, data2[i * mask2.Cols + j]);
                }
            }

            Filter(src, out Mat sharpen1, mask1);
            Filter(src, out Mat sharpen2, mask2);

            sharpen1.ConvertTo(sharpen1, MatType.CV_8U);
            sharpen2.ConvertTo(sharpen2, MatType.CV_8U);

            Cv2.ImShow("sharpen1", sharpen1);
            Cv2.ImShow("sharpen2", sharpen2);
            Cv2.ImShow("src", src);

            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


- 원본 사진

![image](https://github.com/user-attachments/assets/64a6351d-a50b-49af-a13e-6e0e72744da1)


- sharpen1


![image](https://github.com/user-attachments/assets/a1d25acc-1a37-47ed-aa52-44a0a14f87ff)


- sharpen2


![image](https://github.com/user-attachments/assets/517e48ce-1b6e-445a-bc2a-0e022a53b925)



### - Filter2D 함수 사용해 샤프닝


OpenCV의 내장 함수인 Cv2.Filter2D()를 사용해 회선 연산을 수행

OpenCV의 Filter2D는 최적화가 되어 있어 직접 코드를 입력하는 것 보다 빠르게 실행된다.


```
using OpenCvSharp;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace ShapeningDirect
{
    internal class Program
    {
        static void Main(string[] args)
        {
            string path = @"C:\\Temp\\cv_imgs\\filter_sharpen.jpg";
            Mat src = Cv2.ImRead(path, ImreadModes.Grayscale);

            if (src.Empty())
                throw new Exception("Failed to load image");

            float[] data1 =
            {
                0, -1, 0,
                -1, 5, -1,
                0, -1, 0
            };

            float[] data2 =
            {
                -1, -1, -1,
                -1, 9, -1,
                -1, -1, -1
            };

            // 마스크(필터) 설정
            // 3x3 크기의 샤프닝 필터를 정의하고, 각 마스크에 샤프닝 커널 값을 설정합니다.
            // data1과 data2는 각각 약한 샤프닝과 강한 샤프닝을 수행합니다.
            Mat mask1 = new Mat(3, 3, MatType.CV_32F);
            Mat mask2 = new Mat(3, 3, MatType.CV_32F);

            // data1 값을 mask1에 설정
            for (int i = 0; i < mask1.Rows; i++)
            {
                for (int j = 0; j < mask1.Cols; j++)
                {
                    mask1.Set<float>(i, j, data1[i * mask1.Cols + j]);
                }
            }

            // data2 값을 mask2에 설정
            for (int i = 0; i < mask2.Rows; i++)
            {
                for (int j = 0; j < mask2.Cols; j++)
                {
                    mask2.Set<float>(i, j, data2[i * mask2.Cols + j]);
                }
            }

            Mat sharpen1 = new Mat();
            Mat sharpen2 = new Mat();

            Cv2.Filter2D(src, sharpen1, MatType.CV_32F, mask1);
            Cv2.Filter2D(src, sharpen2, MatType.CV_32F, mask2);

            // 결과를 CV_8U로 변환
            sharpen1.ConvertTo(sharpen1, MatType.CV_8U);
            sharpen2.ConvertTo(sharpen2, MatType.CV_8U);

            Cv2.ImShow("sharpen1", sharpen1);
            Cv2.ImShow("sharpen2", sharpen2);
            Cv2.ImShow("src", src);

            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


- 원본 사진

![image](https://github.com/user-attachments/assets/c6e61f94-a372-457d-b984-532d6883147f)


- sharpen1


![image](https://github.com/user-attachments/assets/50e674ae-660a-4376-9890-b2f449eeb329)


- sharpen2


![image](https://github.com/user-attachments/assets/14fa31f5-a321-468f-9ea5-1b034211b6ae)



### - Roberts edge detection


Roberts Edge 검출이란?

: 이미지에서 경계를 감지하기 위한 방법 중 하나입니다. 차이 연산을 기반으로 하는 간단한 기법으로, 교차하는 두 방향(대각선)의 픽셀 차이를 구해 에지를 검출합니다.


이 코드는 주어진 이미지를 그레이스케일로 읽고, 3x3 크기의 차이 연산을 통해 에지 정보를 추출한 후, 결과를 출력합니다.


```
using System;
using OpenCvSharp;

namespace _20241024_RobertsMask
{
    internal class Program
    {
        // DifferOp 함수: 에지 검출 연산
        static void DifferOp(Mat img, out Mat dst, int maskSize)
        {
            dst = new Mat(img.Size(), MatType.CV_8U, Scalar.All(0));
            Point h_m = new Point(maskSize / 2, maskSize / 2);

            for (int i = h_m.Y; i < img.Rows - h_m.Y; i++)
            {
                for (int j = h_m.X; j < img.Cols - h_m.X; j++)
                {
                    List<byte> mask = new List<byte>();

                    for (int u = 0; u < maskSize; u++)
                    {
                        for (int v = 0; v < maskSize; v++)
                        {
                            int y = i + u - h_m.Y;
                            int x = j + v - h_m.X;
                            mask.Add(img.At<byte>(y, x));
                        }
                    }

                    byte max = 0;
                    for (int k = 0; k < mask.Count / 2; k++)
                    {
                        int start = mask[k];
                        int end = mask[mask.Count - k - 1];

                        byte difference = (byte)Math.Abs(start - end);
                        if (difference > max) max = difference;
                    }

                    dst.Set<byte>(i, j, max);
                }
            }
        }

        // 메인 함수: 이미지 로드 및 필터 적용
        static void Main(string[] args)
        {
            string path = @"C:\\Temp\\cv_imgs\\edge_test.jpg";
            Mat src = Cv2.ImRead(path, ImreadModes.Grayscale);

            if (src.Empty())
                throw new Exception("Failed to load image");

            Mat edge;
            DifferOp(src, out edge, 3);

            // 결과 출력
            Cv2.ImShow("src", src);
            Cv2.ImShow("edge", edge);

            Cv2.WaitKey(); Cv2.DestroyAllWindows();
        }
    }
}
```


### - 실행 결과


- 원본 이미지


![image](https://github.com/user-attachments/assets/28372785-5466-42fa-bd6c-de996563db15)


- edge detection 이미지


![image](https://github.com/user-attachments/assets/af54106f-75b0-48be-86c0-173beb38f790)


### - Edge Detect by using Sobel Filter


```
using OpenCvSharp;

namespace _20241024_SobelMask
{
    internal class Program
    {
        static void Differential(Mat image, out Mat dst, float[] data1, float[] data2)
        {
            Mat mask1 = new Mat(3, 3, MatType.CV_32F);
            Mat mask2 = new Mat(3, 3, MatType.CV_32F);
            

            // data1 값을 mask1에 설정
            // data1은 수직 방향 에지를 검출하는 마스크로, 픽셀 값의 수평 차이를 계산합니다.
            for (int i = 0; i < mask1.Rows; i++)
            {
                for (int j = 0; j < mask1.Cols; j++)
                {
                    mask1.Set<float>(i, j, data1[i * mask1.Cols + j]);
                }
            }

            // data2 값을 mask2에 설정
            // data2는 수평 방향 에지를 검출하는 마스크로, 픽셀 값의 수직 차이를 계산합니다.
            for (int i = 0; i < mask2.Rows; i++)
            {
                for (int j = 0; j < mask2.Cols; j++)
                {
                    mask2.Set<float>(i, j, data2[i * mask2.Cols + j]);
                }
            }

            Mat dst1 = new Mat();
            Mat dst2 = new Mat();
            dst = new Mat();

            // OpenCV Filter2D를 사용하여 회선 연산 수행
            Cv2.Filter2D(image, dst1, MatType.CV_32F, mask1); 
            Cv2.Filter2D(image, dst2, MatType.CV_32F, mask2);

            //에지 크기 계산
            // Cv2.Magnitude() 함수는 수직 및 수평 방향에서의 에지 크기(gradient magnitude)를 계산합니다.
            // 에지 크기는 수직 방향과 수평 방향의 차이를 이용해 계산되며, 이를 통해 에지가 얼마나 강한지를 알 수 있습니다.
            Cv2.Magnitude(dst1, dst2, dst);

            // 계산된 값을 CV_8U 형식으로 변환해 출력 이미지로 사용
            dst.ConvertTo(dst, MatType.CV_8U);

            Cv2.ConvertScaleAbs(dst1, dst1);  // 절대값 및 형변환 동시 수행 함수
            Cv2.ConvertScaleAbs(dst2, dst2);
            Cv2.ImShow("dst1 - 수직 마스크", dst1);
            Cv2.ImShow("dst2 - 수평 마스크", dst2);
        }

        // 이미지 로드 및 소벨 필터 적용
        static void Main(string[] args)
        {
            string path = @"C:\\Temp\\cv_imgs\\edge_test1.jpg";
            Mat image = Cv2.ImRead(path, ImreadModes.Grayscale);

            if (image.Empty())
                throw new Exception("Failed to load image");

            // data1과 data2는 각각 수직(Sobel X) 및 수평(Sobel Y) 마스크입니다.
            // 이 마스크는 픽셀 간 차이를 통해 이미지의 에지를 계산합니다.
            float[] data1 =
            {
                -1, 0, 1,
                -2, 0, 2,
                -1, 0, 1
            };
            float[] data2 =
            {
                -1, -2, -1,
                0, 0, 0,
                1, 2, 1
            };

            Mat dst;
            Differential(image, out dst, data1, data2);  // 두 방향 소벨 회선 및 크기 계산

            // OpenCV 제공 소벨 에지 계산
            // OpenCV에서 제공하는 Sobel 필터를 사용하여, 수직(dst3) 및 수평(dst4) 방향에서의 에지를 계산합니다.
            Mat dst3 = new Mat();
            Mat dst4 = new Mat();

            Cv2.Sobel(image, dst3, MatType.CV_32F, 1, 0, 3);  // x방향 미분 - 수직 마스크
            Cv2.Sobel(image, dst4, MatType.CV_32F, 0, 1, 3);  // y방향 미분 - 수평 마스크
            Cv2.ConvertScaleAbs(dst3, dst3);  // 절대값 및 uchar 형변환
            Cv2.ConvertScaleAbs(dst4, dst4);

            Cv2.ImShow("image", image);
            Cv2.ImShow("소벨에지", dst);
            Cv2.ImShow("dst3-수직_OpenCV", dst3);
            Cv2.ImShow("dst4-수평_OpenCV", dst4);

            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


- 원본 이미지


![image](https://github.com/user-attachments/assets/5d0ced39-94bf-47e3-a0df-3953eb33d5ce)


- dst1


![image](https://github.com/user-attachments/assets/337ed85f-c985-495c-87b0-f93f99fc1502)


- dst2


![image](https://github.com/user-attachments/assets/aec5e0ab-f9b9-4080-8c2c-cdb850fa3042)


- dst3


![image](https://github.com/user-attachments/assets/c2f07acc-a446-4b73-9874-f506e1aee287)


- dst4


![image](https://github.com/user-attachments/assets/540ba8c4-7de7-4bfc-b7ac-a0f8507cea98)


- 소벨에지


![image](https://github.com/user-attachments/assets/bb5d217c-91c6-49ba-91bb-3730990dd74d)


### - 


```
using OpenCvSharp;

namespace _20241024_LoGDoGTest
{
    internal class Program
    {
        static Mat GetLoGMask(Size size, double sigma)
        {
            double ratio = 1 / (Math.PI * Math.Pow(sigma, 4.0));
            int center = size.Height / 2;
            Mat dst = new Mat(size, MatType.CV_64F);

            for (int i = 0; i < size.Height; i++)
            {
                for (int j = 0; j < size.Width; j++)
                {
                    int x2 = (j - center) * (j - center);
                    int y2 = (i - center) * (i - center);

                    double value = (x2 + y2) / (2 * sigma * sigma);
                    dst.Set(i, j, -ratio * (1 - value) * Math.Exp(-value));
                }
            }

            double scale = (center * 10 / ratio);
            dst *= scale;
            return dst;
        }

        static void Main(string[] args)
        {
            string path = @"C:\\Temp\\cv_imgs\\laplacian_test.jpg";
            Mat image = Cv2.ImRead(path, ImreadModes.Grayscale);

            if (image.Empty())
                throw new Exception("Failed to load image");

            //sigma값이 작으면 필터는 더 날카로워지고 커지면 더 부드럽게 되어 넓은 영역을 흐리게 함 
            double sigma = 1.4;
            Mat logMask = GetLoGMask(new Size(9, 9), sigma);

            Console.WriteLine(logMask);
            Console.WriteLine(Cv2.Sum(logMask));

            Mat dst1 = new Mat();
            Mat dst2 = new Mat();
            Mat gausImg = new Mat();

            // LoG 필터 적용
            Cv2.Filter2D(image, dst1, MatType.CV_32F, logMask);
            Cv2.GaussianBlur(image, gausImg, new Size(9, 9), sigma, sigma);
            Cv2.Laplacian(gausImg, dst2, MatType.CV_32F, 5);

            // DoG 계산
            Mat dst3 = new Mat();
            Mat dst4 = new Mat();
            Cv2.GaussianBlur(image, dst3, new Size(1, 1), 0.0);
            Cv2.GaussianBlur(image, dst4, new Size(9, 9), 1.6);
            Mat dstDoG = new Mat();
            Cv2.Subtract(dst3, dst4, dstDoG);

            Cv2.Normalize(dstDoG, dstDoG, 0, 255, NormTypes.MinMax);

            // 결과 출력
            Cv2.ImShow("image", image);
            Cv2.ImShow("dst1 - LoG_filter2D", dst1);
            Cv2.ImShow("dst2 - LOG_OpenCV", dst2);
            Cv2.ImShow("dst_DoG - DOG_OpenCV", dstDoG);
            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


```
Mat [ 9*9*CV_64FC1, IsContinuous=True, IsSubmatrix=False, Ptr=0x174eaae7a60, Data=0x174ea9b20c0 ]
Scalar { Val0 = -6.1281673942813955, Val1 = 0, Val2 = 0, Val3 = 0 }
```


- 원본 이미지


![image](https://github.com/user-attachments/assets/74112a03-e79d-45a8-9b80-5fb83c2d34c9)


- dst1 LoG filter 2D


![image](https://github.com/user-attachments/assets/0a3256f8-c0a8-40db-9504-d44bf29960eb)


- dst2 LOG OpenCV


![image](https://github.com/user-attachments/assets/1872a49f-3091-47a3-a486-0c7e59895bde)


- dst_DoG DOG OpenCV


![image](https://github.com/user-attachments/assets/d1be53f7-aba2-45e4-a09d-67327af81c77)



### - Canny Edge Detection


```
using OpenCvSharp;
using System;
using System.Collections.Generic;

namespace CannyEdge
{
    internal class Program
    {
        // 방향성을 계산하는 함수
        static void CalcDirect(Mat Gy, Mat Gx, out Mat direct)
        {
            direct = new Mat(Gy.Size(), MatType.CV_8U, Scalar.All(0));

            for (int i = 0; i < direct.Rows; i++)
            {
                for (int j = 0; j < direct.Cols; j++)
                {
                    // 해당 픽셀의 x, y 방향의 기울기를 가져옴
                    float gx = Gx.At<float>(i, j);
                    float gy = Gy.At<float>(i, j);
                    // atan2를 사용해 각도를 구하고 45로 나눔
                    int theta = (int)(Cv2.FastAtan2(gy, gx) / 45);
                    direct.Set<byte>(i, j, (byte)(theta % 4));
                }
            }
        }

        // 최대 억제(non-maximum suppression)를 수행하는 함수
        static void SuppNonMax(Mat sobel, Mat direct, out Mat dst)
        {
            dst = new Mat(sobel.Size(), MatType.CV_32F, Scalar.All(0));

            for (int i = 1; i < sobel.Rows - 1; i++)
            {
                for (int j = 1; j < sobel.Cols - 1; j++)
                {
                    // 방향성 값을 기반으로 인접 픽셀의 값을 가져옴
                    int dir = direct.At<byte>(i, j);
                    float v1, v2;

                    if (dir == 0)
                    {
                        v1 = sobel.At<float>(i, j - 1);
                        v2 = sobel.At<float>(i, j + 1);
                    }
                    else if (dir == 1)
                    {
                        v1 = sobel.At<float>(i + 1, j + 1);
                        v2 = sobel.At<float>(i - 1, j - 1);
                    }
                    else if (dir == 2)
                    {
                        v1 = sobel.At<float>(i - 1, j);
                        v2 = sobel.At<float>(i + 1, j);
                    }
                    else
                    {
                        v1 = sobel.At<float>(i + 1, j - 1);
                        v2 = sobel.At<float>(i - 1, j + 1);
                    }

                    float center = sobel.At<float>(i, j);
                    // 중심 픽셀이 인접 픽셀보다 큰 경우에만 값을 보존
                    dst.Set<float>(i, j, (center > v1 && center > v2) ? center : 0);
                }
            }
        }

        // 임계값을 기반으로 엣지 트레이싱을 수행하는 함수
        static void Trace(Mat maxSo, Mat posCk, Mat hyImg, Point pt, int low)
        {
            Rect rect = new Rect(new Point(0, 0), posCk.Size());
            if (!rect.Contains(pt)) return;

            if (posCk.At<byte>(pt.Y, pt.X) == 0 && maxSo.At<float>(pt.Y, pt.X) > low)
            {
                posCk.Set<byte>(pt.Y, pt.X, 1);
                hyImg.Set<byte>(pt.Y, pt.X, 255);

                List<Point> points = new List<Point>
        {
            new Point(-1, -1), new Point(0, -1), new Point(1, -1),
            new Point(-1, 0), new Point(1, 0),
            new Point(-1, 1), new Point(0, 1), new Point(1, 1)
        };

                foreach (var point in points)
                {
                    Trace(maxSo, posCk, hyImg, pt + point, low);
                }
            }
        }

        // 이중 임계값 처리를 수행하는 함수
        static void HysteresisTh(Mat maxSo, out Mat hyImg, int low, int high)
        {
            Mat posCk = new Mat(maxSo.Size(), MatType.CV_8U, Scalar.All(0));
            hyImg = new Mat(maxSo.Size(), MatType.CV_8U, Scalar.All(0));

            for (int i = 0; i < maxSo.Rows; i++)
            {
                for (int j = 0; j < maxSo.Cols; j++)
                {
                    if (maxSo.At<float>(i, j) > high)
                        Trace(maxSo, posCk, hyImg, new Point(j, i), low);
                }
            }
        }

        static void Main(string[] args)
        {
            // 이미지를 불러옴
            Mat image = Cv2.ImRead("c:\\Temp\\cv_imgs\\newjeans.jpg", ImreadModes.Grayscale);
            if (image.Empty()) throw new Exception("이미지 로딩 실패!");

            Mat gauImg = new Mat();
            Mat Gx = new Mat();
            Mat Gy = new Mat();
            Mat direct = new Mat();
            Mat sobel = new Mat();
            Mat maxSobel = new Mat();
            Mat hyImg = new Mat();
            Mat canny = new Mat();

            // 가우시안 블러 처리
            Cv2.GaussianBlur(image, gauImg, new Size(5, 5), 0.3);
            // Sobel 필터로 엣지 감지
            Cv2.Sobel(gauImg, Gx, MatType.CV_32F, 1, 0, 3);
            Cv2.Sobel(gauImg, Gy, MatType.CV_32F, 0, 1, 3);
            sobel = Gx.Abs() + Gy.Abs();

            CalcDirect(Gy, Gx, out direct);
            SuppNonMax(sobel, direct, out maxSobel);
            HysteresisTh(maxSobel, out hyImg, 100, 150);

            // OpenCV의 Canny 함수로 엣지 감지
            Cv2.Canny(image, canny, 100, 150);

            // 결과 표시
            Cv2.ImShow("이미지", image);
            Cv2.ImShow("캐니", hyImg);
            Cv2.ImShow("OpenCV 캐니", canny);
            Cv2.WaitKey();
        }
    }
}
```


### - 실행 결과


- 원본 이미지


![image](https://github.com/user-attachments/assets/bcc6f3ad-e9e9-4f15-a8e6-0ded9bf83d79)


- 캐니


![image](https://github.com/user-attachments/assets/2323fe38-5ebf-4bc6-9064-b4d555f45ba8)


- OpenCV 캐니


![image](https://github.com/user-attachments/assets/5777bc12-f9dd-44c6-90d4-228857d2e828)



### - 


```

```


### - 실행 결과


```

```

### - 


```

```


### - 실행 결과


```

```

### - 


```

```


### - 실행 결과


```

```

### - 


```

```


### - 실행 결과


```

```

### - 


```

```


### - 실행 결과


```

```

### - 


```

```


### - 실행 결과


```

```

